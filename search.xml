<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[consul配置与实战]]></title>
    <url>%2F2017%2F09%2F16%2Fconsul%2F</url>
    <content type="text"><![CDATA[上一篇提到，项目用的分布式服务发现与注册组件是consul，这篇文章主要来讲下consul组件在项目中的应用以及相关介绍。本文以官方文档为主要参考consul文档。 1. consul介绍consul是一个服务管理软件，主要功能如下： 支持多数据中心下，分布式高可用的，服务发现和配置共享。 consul支持健康检查，允许存储键值对。 一致性协议采用Raft算法,用来保证服务的高可用。 成员管理和消息广播采用GOSSIP协议，支持ACL访问控制。 1.1 服务注册与发现服务注册是一个服务将其位置信息在“中心注册节点”注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，有时也会有服务访问的认证信息，使用协议，版本号，以及关于环境的一些细节信息。而服务发现可以让一个应用或者组件发现其运行环境以及其它应用或组件的信息。用户配置一个服务发现工具就可以将实际容器跟运行配置分离开。常见配置信息包括：ip、端口号、名称等。 在传统情况下，当出现服务存在于多个主机节点上时，都会使用静态配置的方法来实现服务信息的注册。而当在一个复杂的系统里，需要较强的可扩展性时，服务被频繁替换时，为避免服务中断，动态的服务注册和发现就很重要。服务注册与发现的组件有很多，如Zookeeper、Etcd等。既可用于服务间的协调，同时又可用于服务的注册。 1.2 Consensus Protocol - Raft Consul使用Consensus协议Raft提供一致性（Consistency）。本文只是简单介绍在consul中的一致性，后面专门一篇写raft。 首先，Raft是一种基于Paxos的Consensus算法。相比于Paxos，Raft设计采用了较少的状态，并且是一种更简单、更易于理解的算法。只有Server节点参与Raft，且是peer set的一员。所有的Client节点只是转发请求到Server。这种设计的考虑是，当更多的成员加入到peer set中时，quorum的规模也会增加。可能会导致性能问题是等待quorum个节点log entry。 启动Consul时，单个consul节点需要以bootstrap模式运行，该模式运行自我选举为leader。一旦Leader被选出来，其他Server可以添加Peer set中，保持一致性和安全性。最终一些Server添加到集群，bootstrap模式需要禁用。 因为所有Server都是Peer set中的成员，它们都知道谁是Leader。当一个RPC请求到达某个非Leader Server节点，请求就会被转发到Leader。如果RPC是一种query类型，这意味着它是只读的，Leader会基于FSM当前生成相应的结果，如果RPC是一种transaction类型，即修改状态，Leader产生一个新的日志条目，并基于Raft算法进行管理。一旦日志条目应用于有限状态机，transaction完成。 由于Raft的replication性质，性能对网络延迟是非常敏感的。为此，每个数据中心选择独立的Leader和维护一个不关联的peer set。数据按照数据中心进行划分，所以每个Leader只负责在相应数据中心的数据。当接收到一个远程数据中心的请求时，请求会被转发到相应的Leader。这种设计在不牺牲一致性的情况实现较低延迟交易和更高的可用性。虽然所有日志副本的写入都是基于Raft，读取更灵活。但为了支持开发人员可能需要的各种权衡，Consul支持3种不同的一致性模式。 Default，Raft采用Leader租赁模式，提供了一个时间窗口，在该时间段内，Leader角色是稳定的。 consistent，无条件一致性 stale，这种模式允许在任何Server节点执行读取操作，无论它是不是Leader。 1.3 Group Membership Protocol - GossipConsul使用gossip协议管理成员关系、广播消息到整个集群。详情可参考Serf library。 Consul利用两个不同的gossip pool。局域网(LAN Pool)和广域网(WAN Pool)。 每个Consul数据中心都有一个包含所有成员（Server和Client）的LAN gossip pool。LAN Pool有如下几个目的： 首先，成员关系允许Client自动发现Server节点，减少所需的配置量。 其次，分布式故障检测允许的故障检测的工作在某几个Server几点执行，而不是集中整个集群所有节点上。 最后，gossip允许可靠和快速的事件广播，如Leader选举。 WAN Pool是全局唯一的，无论属于哪一个数据中心，所有Server应该加入到WAN Pool。由WAN Pool提供会员信息让Server可节电执行跨数据中心的请求。集成中故障检测允许Consul妥善处理整个数据中心失去连接，或在远程数据中心只是单个的Server节点。所有这些功能都是通过利用Serf提供。从用户角度来看，它是作为一个嵌入式库提供这些功能。但其被Consul屏蔽，用户无需关心。作为开发人员可以去了解这个库是如何利用。 1.4 Session会话上一篇文章snowflake升级版全局id生成中使用到了consul的KV存储。Consul提供session会话机制，可以用于构建分布式锁。session可以绑定到节点、健康检查、KV数据，目的是提供细粒度锁。KV存储和会话的集成是使用会话的主要场景。必须在使用之前创建一个会话，然后使用它的ID。KV API支持acquire和release操作，acquire操作类似CAS操作，只有当锁空闲时才会返回成功。当成功时，某个normal标识会更新，也会递增LockIndex，当然也会更新session的信息。如果在acquire操作时，与session相关的锁已经持有，那么LockIndex就不会递增，但是key值会更新，这就允许锁的当前持有者无需重新获得锁就可以更新key的内容。 一旦获得锁，所需要经release操作来释放（使用相同的session）。Release操作也类似于CAS操作。如果给定的session无效，那么请求会失败。需要特别注意的是，无需经过session的创建者，lock也是可以被释放的。这种设计是允许操作者干预来终止会话，在需要的时候。如上所述，会话无效也将导致所有被持有的锁被释放或删除。当锁被释放时，LockIndex不会变化，但是session会被清空，并且ModifyIndex递增。这些语义允许元组（Key，LockIndex，Session）作为一个独特的“序列”。这个序列可以被传递和用于验证请求是否属于当前的锁持有者。因为每次acquire 都会导致LockIndex递增，即使同一会话中重新获取锁，该序列能够检测到陈旧的请求。同样，如果会话失效，相应的LockIndex将为空。要清楚的是，这种锁系统是纯粹的咨询。并不是强制Client必须获取锁再能执行操作作。任何客户端都可以在未获得锁的情况下读取、写入和删除Key操作。它不是Consul用于保护系统的方法。 2. consul架构上面介绍了consul的技术内幕。现在来讲讲consul的架构。 拆解开这个体系，从每一个组件开始了解。首先，可以看到有两个数据中心，分别标记为“one”和“two”。Consul是支持多数据中心一流，并且是常用业务场景。 每个数据中心都是由Server和client组成。建议有3~5台Server，基于故障处理和性能的平衡之策。如果增加越多的机器，则Consensus会越来越慢。对client没有限制，可以很容易地扩展到成千上万或数万。同一个数据中心的所有节点都要加入Gossip协议。这意味着gossip pool包含给定数据中心的所有节点。有以下目的：首先，没有必要为client配置服务器地址参数；发现是自动完成的。第二，节点故障检测的工作不是放置在服务器上，而是分布式的。这使故障检测比心跳机制更可扩展性。第三，可用来作为消息层通知重要的事件，如leader选举。 每个数据中心的服务器都是属于一个Raft peer。这意味着，他们一起工作，选出一个的Leader，Leader server是有额外的职责。负责处理所有的查询和事务。事务也必须通过Consensus协议复制到所有的伙伴。由于这一要求，当非Leader Server接收到一个RPC请求，会转发到集群的leader。 Server节点也是作为WAN gossip pool的一部分。这个pool是与LAN gossip pool是不同的，它为具有更高延迟的网络响应做了优化，并且可能包括其他consul集群的server节点。设计WANpool的目的是让数据中心能够以low-touch的方式发现彼此。将一个新的数据中心加入现有的WAN Gossip是很容易的。因为池中的所有Server都是可控制的，这也使跨数据中心的要求。当一个Serfer接收到不同的数据中心的要求时，它把这个请求转发给相应数据中心的任一Server。然后，接收到请求的Server可能会转发给Leader。多个数据中心之间是低耦合，但由于故障检测、连接缓存复用、跨数据中心要求快速和可靠的响应。 3. consul部署3.1 docker安装docker安装很简单，笔者这边是基于docker-compose的配置文件，只需要本地安装好docker和docker-compose，docker-compose.yml如下： 12345678version: '3'services: consul: image: consul ports: - "8500:8500" - "8600:8600" - "8300:8300" 拉取consul得最新image，进行端口映射，暴露对外的端口8500，8300. 3.2 软件安装 从官网下载罪行的consul安装包，https://www.consul.io/downloads.html。 解压consul_0.6.4_darwin_amd64.zip。 将解压后的二进制文件consul拷贝到/usr/local/bin下。 写配置文件。服务注册的配置文件如下: 12345678910111213141516&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [&quot;master&quot;], &quot;address&quot;: &quot;1192.168.1.100&quot;, &quot;port&quot;: 8000, &quot;enableTagOverride&quot;: false, &quot;check&quot;: &#123; &quot;id&quot;: &quot;redis&quot;, &quot;name&quot;: &quot;redis on port 8000&quot;, &quot;tcp&quot;: &quot;localhost:8000&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125; &#125;&#125; 如上配置注册了Redis的8000端口，并带有tcp的health check。 节点的配置文件： 12345678910111213141516&#123; "datacenter": "east-cn", "data_dir": "/opt/consul", "log_level": "INFO", "node_name": "redis", "server": true, "addresses": &#123; "https": "192.168.1.100" &#125;, "ports": &#123; "https": 0 &#125;, "ui": true, "retry-join": []&#125; 当加载配置选项时，consul是按照词典顺序从所有配置文件或目录中加载。比如，a.json会先于e.json处理。后面设定的配置选项会合并到前面的配置集合中，如果存在重复的配置选项则会覆盖。当然，在某些情况下，比如事件处理程序，后面处理程序会追加到现有的配置选项中，形成事件处理程序列表。 3.3 启动具体启动文档见configuration。如: consul agent -server -config-dir /etc/consul.d -bind=192.168.1.100 -config-dir /etc/consul.d config-dir需要加载的配置文件目录，consul将加载目录下所有后缀为“.json”的文件，加载顺序为字母顺序，文件中配置选项合并方式如config-file。该参数可以多次配置。目录中的子目录是不会加载的。 data-dir此目录是为Agent存放state数据的。是所有Agent需要的，该目录应该存放在持久存储中（reboot不会丢失），对于server角色的Agent是很关键的,需要记录集群状态。并且该目录是支持文件锁。 server设置Agent是server模式还是client模式。Consul agent有两种运行模式：Server和Client。这里的Server和Client只是Consul集群层面的区分，与搭建在Cluster之上 的应用服务无关。Consule Server模式agent节点用于采用raft算法维护Consul集群的状态，官方建议每个Consul Cluster至少有3个或以上的运行在Server mode的Agent，Client节点不限。 其他常用的还有： client将绑定到client接口的地址，可以是HTTP、DNS、RPC服务器。默认为“127.0.0.1”，只允许回路连接。RPC地址会被其他的consul命令使用，比如consul members，查询agent列表 node节点在集群的名字，在集群中必须是唯一的。默认为节点的Hostname。 bootstrap设置服务是否为“bootstrap”模式。如果数据中心只有1个server agent，那么需要设置该参数。从技术上来讲，处于bootstrap模式的服务器是可以选择自己作为Raft Leader的。在consul集群中，只有一个节点可以配置该参数，如果有多个参数配置该参数，那么难以保证一致性。 bind用于集群内部通信的IP地址，与集群中其他节点互连可通。默认为“0.0.0.0”，consul将使用第一个有效的私有IPv4地址。如果指定“[::]”，consul将使用第一个有效的公共IPv6地址。使用TCP和UDP通信。注意防火墙，避免无法通信。 3.4 结果在开启了&quot;ui&quot;: trueserver主机上，如http://192.168.1.100:8500/ui查看注册中心的服务。demo ui如下： 4. 总结本文介绍了consul的一些内幕及consul配置相关，并对项目中的一些实际配置进行展示。希望能够帮助大家对consul相关的知识有所了解，并对于入门配置consul和实际应用有所知道。个人认为，consul原理还是简单易懂的，集群的配置也不复杂，安利大家使用。后面会再写一篇介绍Spring cloud中集成和使用consul组件作为注册与发现中心。]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>consul</tag>
        <tag>cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[snowflake升级版全局id生成]]></title>
    <url>%2F2017%2F09%2F09%2Fsnowflake%2F</url>
    <content type="text"><![CDATA[1. 背景分布式系统或者微服务架构基本都采用了分库分表的设计，全局唯一id生成的需求变得很迫切。传统的单体应用，使用单库，数据库中自增id可以很方便实现。分库之后，首先需要分库键，分库键必然不能重复，所以传统的做法并不能满足需求。概括下来，那业务系统对ID号的要求有哪些呢？ 1.全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。2.趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。3.单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。4.信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。 其中第3和第4点是互斥的。除了功能性需求，还有性能和可靠性的需求： 平均延迟和TP999延迟都要尽可能低； 可用性5个9； 高QPS。 2. 进阶历程自从项目从单体应用拆分成微服务架构后，对全局id部分做了些摸索。 2.1 uuid刚开始拆分业务，id主键都是使用uuid字符串。UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符。类似这样的字符串：dc5adf0a-d531-11e5-95aa-3c15c2d22392。128位，根本不用担心不够用。生成的方法也很简单： 1UUID userId = UUID.randomUUID(); uuid全球唯一，本地生成，没有网络消耗，产生的性能绝对可以满足。其缺点也是显而易见的，比较占地方，和INT类型相比，存储一个UUID要花费更多的空间。使用UUID后，URL显得冗长，不够友好。ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用： MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求。 对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。 2.2 数据库生成以MySQL举例，利用给字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用下列SQL读写MySQL得到ID号。参考了Leaf的实现思想: id server每次批量从数据库取号段，本地缓存这个号段，并且设置阈值，当达到0.8（已用与号段容量的比值），自动去获取一个新的号段，更新本地缓存的号段。 id client，即具体的调用服务实例，在本地也做一个缓存，实现和id server的缓存差不多，这样做的目的是为了减轻id服务端的压力，同时减少了rpc调用的网络消耗。 以上方案，其缺点是： 号段存在浪费，无论哪个客户端还是服务端重启都会浪费号段。 号段是直接自增，不够随机，对外暴露信息过多。 DB宕机会造成整个系统不可用。虽然在DB宕机之后，利用缓存还能进行短暂供号，但是数据库的依赖还是很重。Leaf采用的一般做法是高可用容灾: 采用一主两从的方式，同时分机房部署，Master和Slave之间采用半同步方式同步数据。同时使用DBProxy做主从切换。当然这种方案在一些情况会退化成异步模式，甚至在非常极端情况下仍然会造成数据不一致的情况，但是出现的概率非常小。 3. snowflake方案3.1 介绍考虑到上述方案的缺陷，笔者调查了其他的生成方案，snowflake就是其中一种方案。趋势递增和不够随机的问题，在snowflake完全可以解决，Snowflake ID有64bits长，由以下三部分组成： 第一位为0，不用。 timestamp—41bits,精确到ms，那就意味着其可以表示长达(2^41-1)/(1000360024*365)=139.5年，另外使用者可以自己定义一个开始纪元（epoch)，然后用(当前时间-开始纪元）算出time，这表示在time这个部分在140年的时间里是不会重复的，官方文档在这里写成了41bits，应该是写错了。另外，这里用time还有一个很重要的原因，就是可以直接更具time进行排序，对于twitter这种更新频繁的应用，时间排序就显得尤为重要了。 machine id—10bits,该部分其实由datacenterId和workerId两部分组成，这两部分是在配置文件中指明的。 datacenterId，方便搭建多个生成uid的service，并保证uid不重复，比如在datacenter0将机器0，1，2组成了一个生成uid的service，而datacenter1此时也需要一个生成uid的service，从本中心获取uid显然是最快最方便的，那么它可以在自己中心搭建，只要保证datacenterId唯一。如果没有datacenterId，即用10bits，那么在搭建一个新的service前必须知道目前已经在用的id，否则不能保证生成的id唯一，比如搭建的两个uid service中都有machine id为100的机器，如果其server时间相同，那么产生相同id的情况不可避免。 workerId是实际server机器的代号，最大到32，同一个datacenter下的workerId是不能重复的。它会被注册到consul上，确保workerId未被其他机器占用，并将host:port值存入，注册成功后就可以对外提供服务了。 sequence id —12bits,该id可以表示4096个数字，它是在time相同的情况下，递增该值直到为0，即一个循环结束，此时便只能等到下一个ms到来，一般情况下4096/ms的请求是不太可能出现的，所以足够使用了。 3.2 实现思路snowflake方案，id服务端生成，不依赖DB，既能保证性能，且生成的id足够随机。每一毫秒，一台worker可以生成4096个id，如果超过，会阻塞到下一毫秒生成。对于那些并发量很大的系统来说,显然是不够的, 那么这个时候就是通过datacenterId和workerId来做区分,这两个ID,分别是5bit,共10bit,最大值是1024(0-1023)个, 在这种情况下,snowflake一毫秒理论上最大能够生成的ID数量是约42W个,这是一个非常大的基数了,理论上能够满足绝大多数系统的并发量。 该方案依赖于系统时钟，需要考虑时钟回拨的问题。本地缓存上一次请求的lastTimestamp，一个线程过来获取id时，首先校验当前时间是否小于上一次ID生成的时间戳。如果小于说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！如此可以解决运行中，系统时钟被修改的问题。 另一种情况是，server服务启动时，系统的时间被回拨（虽然比较极端，还是列在考虑中），这样有可能与之前生成的id冲突，全局不唯一。这边解决方法是利用项目的服务发现与注册组件consul，在consul集群存储最新的lastTimestamp，key为对应的machine-id。consul的一致性基于raft算法，并利用Gossip协议： Consul uses a gossip protocol to manage membership and broadcast messages to the cluster. All of this is provided through the use of the Serf library. 具体的协议算法，可以参考Gossip。每次server实例启动时，实例化id生成bean的时候，会首先校验当前时间与consul集群中该worker对应的lastTimestamp大小，如果当前时间偏小，则抛出异常，服务启动失败并报警。 笔者项目暂时未分data center，所以machine-id部分都是以服务实例的workid代替。workid可以从配置中心获取，也可以本地配置。简化的系统架构部署图如下： consul集群这边作为提供naming service和kv存储的组件，每个服务部署后注册到consul集群，至于consul集群相关的信息，以及consul成员的一致性相关，后面单独一篇文章详细介绍。 请求id生成流程图如下： 服务实例启动的流程图见上文，此处不画出了。这边需要强调的是，服务注册与发现组件consul。部署时每个服务实例都会注册到一个consul agent（一般是本机），consul agent连接到consul集群，通过gossip协议进行广播信息，所以如果连接的consul agent进程不幸挂掉（大多为系统宕机），在进程重启后，还是能迅速获取到集群中存储的该workid的lastTimestamp，针对该workid，如果系统时间回拨小于lastTimestamp，Generator启动时会报警。而对于大于lastTimestamp的情况，可能系统时钟还是相对回拨，我们姑且可以认为对全局id没有影响。 实例化时，进行校验： 123456789public IdServiceImpl(long workerId, ConsulClient consulClient) &#123; if (workerId &gt; idMeta.MAX_ID || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", idMeta.MAX_ID)); &#125; this.workerId = workerId; this.consulClient = consulClient; validateStoredTimestamp(); log.info("worker starting. timestamp left shift &#123;&#125;, worker id bits &#123;&#125;, sequence bits &#123;&#125;, workerid &#123;&#125;", idMeta.TIMESTAMP_LEFT_SHIFT_BITS, idMeta.ID_BITS, idMeta.SEQUENCE_BITS, workerId);&#125; 校验函数： 123456789101112131415/** * checks for timestamp by workerId when server starts. * if server starts for the first time, just let it go and log warns. * if current timestamp is smaller than the value stored in consul server, throw exception. */private void validateStoredTimestamp() &#123; long current = timeGen(); Response&lt;GetValue&gt; keyValueResponse = consulClient.getKVValue(String.valueOf(workerId)); if (keyValueResponse.getValue() != null) &#123; lastTimestamp = Long.parseLong(keyValueResponse.getValue().getDecodedValue()); validateTimestamp(current, lastTimestamp, Periods.START); &#125; else &#123; log.warn(String.format("clock in consul is null. Generator works as for the 1st time.")); &#125;&#125; validateTimestamp: 123456789101112/** * 如果当前时间戳小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ * * @param lastTimestamp 上一次ID生成的时间戳 * @param timestamp 当前时间戳 */ private void validateTimestamp(long timestamp, long lastTimestamp, Periods period) &#123; if (timestamp &lt; lastTimestamp) &#123; log.error(String.format("clock is moving backwards. Rejecting requests until %d.", lastTimestamp)); throw new IllegalStateException(String.format("Clock moved backwards in %s. Refusing to generate id for %d milliseconds", period, lastTimestamp - timestamp)); &#125; &#125; 获取id方法： 123456789101112131415161718192021222324252627/** * 生成ID（线程安全） * * @return id */ public synchronized long genId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ validateTimestamp(timestamp, lastTimestamp, Periods.RUNNING); //如果是同一时间生成的，则进行毫秒内sequence生成 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; IdMeta.SEQUENCE_MASK; //溢出处理 if (sequence == 0) &#123;//阻塞到下一毫秒,获得新时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123;//时间戳改变，毫秒内sequence重置 sequence = 0L; &#125; //上次生成ID时间截 lastTimestamp = timestamp; consulClient.setKVValue(String.valueOf(workerId), String.valueOf(lastTimestamp)); //移位并通过或运算组成64位ID return ((timestamp - idMeta.START_TIME) &lt;&lt; idMeta.TIMESTAMP_LEFT_SHIFT_BITS) | (workerId &lt;&lt; idMeta.ID_SHIFT_BITS) | sequence; &#125; 4. 总结这篇文章和大家分享了笔者项目中全局id生成服务的演进过程。当前的方案可以满足笔者当前项目的需求，至于分data-center（同一个机房优先调用），需要结合rpc调用进一步做处理，所以这块后续可以继续完善。欢迎大家提出建议。 参考： www.consul.io leaf Twitter的分布式自增ID算法snowflake (Java版)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>id</tag>
        <tag>spring boot</tag>
        <tag>snowflake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入ThreadLocal]]></title>
    <url>%2F2017%2F09%2F04%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal主要是提供线程内部的局部变量，在每个线程内随时随地可取，隔离其他线程。 1. ThreadLocal接口1.1 ThreadLocal类接口很简单，只有4个方法，我们先来了解一下： void set(Object value)设置当前线程的线程局部变量的值。 public Object get()该方法返回当前线程所对应的线程局部变量。 public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。 protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。 1.2 使用ThreadLocal123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ThreadTest &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;()&#123; protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125; &#125;; ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;()&#123;; protected String initialValue() &#123; return Thread.currentThread().getName(); &#125; &#125;; public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final ThreadTest test = new ThreadTest(); //test.set(); System.out.println("main.getLong: " + test.getLong()); System.out.println("main.getString: " + test.getString()); Thread thread1 = new Thread() &#123; public void run() &#123; //test.set(); System.out.println("Thread.getLong: " + test.getLong()); System.out.println("Thread.getString: " + test.getString()); &#125; &#125;; thread1.start(); thread1.join(); &#125;&#125; 以上demo覆写了initialValue()方法，或者调用set方法，否则会报空指针异常。在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。 2. ThreadLocalMapThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为键值。 1. 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 2. 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal； 3. 在进行get之前，必须先set，否则会报空指针异常； 2.1 方法分析1). JDK8的ThreadLocal的get方法的源码 123456789101112131415161718192021/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 2). getMap 12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 3). setInitialValue 12345678910111213141516/** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; get方法的流程是这样的： 1.首先获取当前线程 2.根据当前线程获取一个Map 3.如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的value e，否则转到5 4.如果e不为null，则返回e.value，否则转到5 5.Map为空或者e为空，则通过initialValue函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map 每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。 3. WeakReference关于内存泄露： ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：ThreadLocal Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 主要看下getEntryAfterMiss函数： 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null; &#125; ThreadLocalMap的getEntry函数的流程： 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode &amp; (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e； 如果e为null或者key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则，如果key值为null，则擦除该位置的Entry，否则继续向下一个位置查询 在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。仔细研究代码可以发现，set操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。 但是光这样还是不够的，上面的设计思路依赖一个前提条件：要调用ThreadLocalMap的genEntry函数或者set函数。这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除不再需要的ThreadLocal，防止内存泄露。所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。 参考：ThreadLocal和synchronized的区别Java并发编程：深入剖析ThreadLocal]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Thread</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自制Jersey-Swagger的spring-boot-starter]]></title>
    <url>%2F2017%2F09%2F02%2Fspring-boot-starter-swaggerforjersey%2F</url>
    <content type="text"><![CDATA[Spring Boot的自动化配置特性来实现快速的将swagger2引入spring boot应用来生成jersey的API文档，简化原生使用swagger2的整合代码。 欢迎使用和Star支持，如使用过程中碰到问题，可以提出Issue，我会尽力完善该Starter 版本基础 Spring Boot：1.5.x swagger-jersey2-jaxrs：2.7.x Jersey 2 如何使用在该项目的帮助下，我们的Spring Boot可以轻松的引入swagger2，主需要做下面两个步骤： 在pom.xml中引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;club.hacloud&lt;/groupId&gt; &lt;artifactId&gt;jersey-starter-swagger&lt;/artifactId&gt; &lt;version&gt;1.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在应用主类中增加@EnableSwagger2Doc注解 123456789@EnableSwagger2Doc@SpringBootApplicationpublic class Bootstrap &#123; public static void main(String[] args) &#123; SpringApplication.run(Bootstrap.class, args); &#125;&#125; JerseyConfig 中增加1234@PostConstructpublic void init() &#123; this.register(ApiListingResource.class, SwaggerSerializers.class);&#125; 默认情况下就能产生所有当前jersey加载的请求映射文档。 参数配置更细致的配置内容参考如下： 配置示例1234567891011swagger: enabled: true title: spring-boot-starter-swagger config-id: demo-mvc version: v2 license: Apache License, Version 2.0 licenseUrl: https://www.apache.org/licenses/LICENSE-2.0.html termsOfServiceUrl: http://git.oschina.net/keets/jersey-starter-swagger contact: keets base-path: /** resource-package: cn.keets.demo 配置说明默认配置12345678910- swagger.enabled=是否开启 // todo 实现线上关闭功能- swagger.title=标题- swagger.description=描述- swagger.version=版本- swagger.license=许可证- swagger.licenseUrl=许可证URL- swagger.termsOfServiceUrl=服务条款URL- swagger.contact=维护人- swagger.resource-package=swagger扫描的基础包，默认：全扫描- swagger.base-path=需要处理的基础URL规则，默认：/** swagger ui未包含在项目中，大家可以自己部署静态文件，通过静态文件解析json 如下图所示： 项目git地址：http://git.oschina.net/keets/jersey-starter-swaggerdemo git地址：http://git.oschina.net/keets/spring-boot-samples/tree/master/demo-jersey-starter 参考：spring-boot-starter-swagger 1.3.0.RELEASE：新增对JSR-303的支持和host的配置]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>starter</tag>
        <tag>spring-boot</tag>
        <tag>swagger</tag>
        <tag>jersey</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Restful Layer of SpringMVC vs Jersey]]></title>
    <url>%2F2017%2F08%2F30%2FJerseyvsspringmvc%2F</url>
    <content type="text"><![CDATA[笔者项目实现前后端剥离，服务端对外提供restful接口。REST逐渐成为影响Web框架、Web协议与Web应用设计的重要概念。现在有越来越多的公司希望能以简单而又贴合Web架构本身的方式公开Web API，因此REST变得越来越重要也就不足为奇了。使用Ajax进行通信的富浏览器端也在朝这个目标不断迈进。这个架构原则提升了万维网的可伸缩性，无论何种应用都能从该原则中受益无穷。SpringMVC和Jersey都可以为你提供restful风格的接口。本文将介绍SpringMVC中的REST特性并与Jersey进行对比。 1. REST基础概念 在REST中的一切都被认为是一种资源。 每个资源由URI标识。 使用统一的接口。处理资源使用POST，GET，PUT，DELETE操作类似创建，读取，更新和删除（CRUD）操作。 无状态。每个请求是一个独立的请求。从客户端到服务器的每个请求都必须包含所有必要的信息，以便于理解。 通信都是通过展现。例如XML，JSON。 2. Jersey与SpringMVCJAX-RS（JSR 311）指的是Java API for RESTful Web Services，Roy Fielding也参与了JAX-RS的制订，他在自己的博士论文中定义了REST。对于那些想要构建RESTful Web Services的开发者来说，JAX-RS给出了不同于JAX-WS（JSR-224）的另一种解决方案。目前共有4种JAX-RS实现，所有这些实现都支持Spring，Jersey则是JAX-RS的参考实现。 有必要指出JAX-RS的目标是Web Services开发（这与HTML Web应用不同）而Spring MVC的目标则是Web应用开发。Spring 3为Web应用与Web Services增加了广泛的REST支持，但本文则关注于与Web Services开发相关的特性。我觉得这种方式更有助于在JAX-RS的上下文中讨论Spring MVC。 要说明的第二点是我们将要讨论的REST特性是Spring Framework的一部分，也是现有的Spring MVC编程模型的延续，因此，并没有所谓的“Spring REST framework”这种概念，有的只是Spring和Spring MVC。这意味着如果你有一个Spring应用的话，你既可以使用Spring MVC创建HTML Web层，也可以创建RESTful Web Services层。]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>REST</tag>
        <tag>Jersey</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac下快速进入当前目录iterm2]]></title>
    <url>%2F2017%2F08%2F28%2Fmac%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[win环境下，有直接在文件浏览的地址上，直接输入cmd，即可打开cmd命令框。笔者在macOS下，也想实现这样的功能，网上查了一下，可以成功实践。 1. 添加服务1git clone https://github.com/peterldowns/iterm2-finder-tools.git 进入 iterm2-finder-tools文件夹，运行iTerm.workflow。安装服务栏。 2. 使用服务在工作文件夹上右键，弹出窗口中找到服务一栏，将鼠标放置其上，在弹出窗口中找到 Open iTerm一栏，单击即可。 3. 添加快捷键服务-&gt;偏好设置-&gt;快捷键 笔者设置了control+command+L。大家可以根据自己的喜好进行设置快捷键。 参考： Mac在Finder中当前目录下打开iTerm2]]></content>
      <categories>
        <category>Utils</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 2实际应用]]></title>
    <url>%2F2017%2F08%2F27%2Fhttp2%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1. 背景介绍1.1 需要解决的问题本文来源于项目需要，项目所使用微服务框架为Spring Cloud，微服务之间的调用基于HTTP 1.X协议，上一篇文章 HTTPS vs HTTP 1.1 vs HTTP 2，介绍了http2 和http1.1的相关知识，也列出了http1.1局限性，链路不能复用、数据不加密、头信息过多等等。为此，笔者在想能不能将feign client的调用基于http2协议，做了如下调研。 HTTP/2 源自 SPDY/2。SPDY 系列协议由谷歌开发，于 2009 年公开。它的设计目标是降低 50% 的页面加载时间。当下很多著名的互联网公司，例如百度、淘宝、UPYUN 都在自己的网站或 APP 中采用了 SPDY 系列协议（当前最新版本是 SPDY/3.1），因为它对性能的提升是显而易见的。主流的浏览器（谷歌、火狐、Opera）也都早已经支持 SPDY，它已经成为了工业标准，HTTP Working-Group 最终决定以 SPDY/2 为基础，开发 HTTP/2。2013年8月，进行首次测试，诞生的时间很晚，笔者搜索了网上关于http2实践的相关信息，发现并不多。 1.2 关于项目介绍Spring Cloud是笔者项目采用的微服务框架，具体介绍见Spring Cloud。Spring Cloud是基于Spring Boot开发的组合框架，Spring Boot内置的容器是Tomcat，笔者的项目一般都会exclude Tomcat的引用，使用的是Jetty容器。所以搜索的主题词就变成了 jetty http2。 2. 调研结果大部分的人习惯于将Tomcat运行在8080端口，再用Apache server在前面提供https。这样做是因为简单且验证过的方法。使用http2 ，你将被迫使用https，这样就不用部署Apache (or nginx)。 2.1 服务端 Currently Jetty and undertow are the only servers in Spring Boot that support HTTP/2.Jetty has booked some progress and this repository shows an excellent example. In my opinion it’s still too much custom code, but they’re getting there.The next candidate is undertow. It seems almost too easy, but it works. Because we use AJP in our current configuration it even means this HTTP/2 solution has less lines of code! 当前Spring Boot只有Jetty 和 undertow支持HTTP/2。 样例repo是一个很好的example。总得分为三步： update dependencies org.springframework.boot:spring-boot-starter-undertow org.mortbay.jetty.alpn:alpn-boot:8.1.8.v20160420 create a servlet container bean 1234567@Bean UndertowEmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; UndertowEmbeddedServletContainerFactory factory = new UndertowEmbeddedServletContainerFactory(); factory.addBuilderCustomizers( builder -&gt; builder.setServerOption(UndertowOptions.ENABLE_HTTP2, true)); return factory; &#125; start your server with alpn为了启动服务，需要带上 -Xbootclasspath 参数来包括alpn 。因为alpn 有可能在jdk中没有。 1-Xbootclasspath/p:/home/harrie/.m2/repository/org/mortbay/jetty/alpn/alpn-boot/8.1.8.v20160420/alpn-boot-8.1.8.v20160420.jar 2.2 客户端 Currently Java HTTP/2 clients are scarce. According to this wiki Netty and OkHttp are the only two implementations supported by Spring. To switch HTTP-client in RestTemplate you have to call the constructor with a different ClientHttpRequestFactory (either Netty4ClientHttpRequestFactory or OkHttpClientHttpRequestFactory). 当前Java的http2的客户端也很少，Spring只有Netty and OkHttp支持。这边我们选用了OkHttp，因为OkHttp本来就有在feign client中内置。 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.3.0.RC1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.0.RC1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt; 2.3 浏览器对于HTTP/2的支持通过浏览器支持http2查看。 2.4 okhttp目前, Http/1.1在全世界大范围的使用中, 直接废弃跳到http/2肯定不现实. 不是每个用户的浏览器都支持http/2的, 也不是每个服务器都打算支持http/2的, 如果我们直接发送http/2格式的协议, 服务器又不支持, 那不是挂掉了! 总不能维护一个全世界的网站列表, 表示哪些支持http/2, 哪些不支持?为了解决这个问题, 从稍高层次上来说, 就是为了更方便地部署新协议, HTTP/1.1 引入了 Upgrade 机制. 这个机制在 RFC7230 的「6.7 Upgrade」这一节中有详细描述.简单说来, 就是先问下你支持http/2么? 如果你支持, 那么接下来我就用http/2和你聊天. 如果你不支持, 那么我还是用原来的http/1.1和你聊天. 客户端在请求头部中指定Connection和Upgrade两个字段发起 HTTP/1.1 协议升级. HTTP/2 的协议名称是 h2c, 代表 HTTP/2 ClearText. 如果服务端不同意升级或者不支持 Upgrade 所列出的协议，直接忽略即可（当成 HTTP/1.1 请求，以 HTTP/1.1 响应）. 如果服务端同意升级，那么需要这样响应 HTTP/1.1 101 Switching ProtocolsConnection: UpgradeUpgrade: h2c[ HTTP/2 connection … ] HTTP Upgrade 响应的状态码是 101，并且响应正文可以使用新协议定义的数据格式。 这样就可以完成从http/1.1升级到http/2了. 同样也可以从http/1.1升级到WebSocket.OkHttp使用了请求协议的协商升级, 无论是1.1还是2, 都先只以1.1来发送, 并在发送的信息头里包含协议升级字段. 接下来就看服务器是否支持协议升级了. OkHttp使用的协议升级字段是ALPN, 如果有兴趣, 可以更深入的查阅相关资料. 3. 总结总体看来，现在Spring boot 是可以支持HTTP/2 server和client。现有项目的api接口面向移动端和web端，web浏览器对于http2的支持在上文已经说明。 参考资料：OkHttp使用完全教程Spring Boot with HTTP/2 – Start a server and make REST calls as a clientHTTPS 与 HTTP2 协议分析]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>HTTP2</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS vs HTTP 1.1 vs HTTP 2]]></title>
    <url>%2F2017%2F08%2F26%2FHTTP2%2F</url>
    <content type="text"><![CDATA[1. HTTPS协议原理分析1.1 需要解决的问题 身份验证:确保通信双方身份的真实性。 通信加密:通信的机密性、完整性依赖于算法与密钥，通信双方是如何选择算法与密钥的。 1.2相关概念 数字证书 CA（certification authority）:数字证书的签发机构。 HTTPS协议、SSL协议、TLS协议、握手协议的关系 HTTPS是Hypertext Transfer Protocol over Secure Socket Layer的缩写，即HTTP over SSL，可理解为基于SSL的HTTP协议。 HTTPS协议安全是由SSL协议（目前常用的，本文基于TLS 1.2进行分析）实现的。 SSL协议是一种记录协议，扩展性良好，可以很方便的添加子协议，而握手协议便是SSL协议的一个子协议。 TLS协议是SSL协议的后续版本，本文中涉及的SSL协议默认是TLS协议1.2版本。 HTTPS协议的安全性由SSL协议实现，当前使用的TLS协议1.2版本包含了四个核心子协议：握手协议、密钥配置切换协议、应用数据协议及报警协议。 1.3 握手协议握手协议的作用便是通信双方进行身份确认、协商安全连接各参数（加密算法、密钥等），确保双方身份真实并且协商的算法与密钥能够保证通信安全。协议交互图： ClientHello消息的作用是，将客户端可用于建立加密通道的参数集合，一次性发送给服务端。 ServerHello消息的作用是，在ClientHello参数集合中选择适合的参数，并将服务端用于建立加密通道的参数发送给客户端。 Certificate消息的作用是，将服务端证书的详细信息发送给客户端，供客户端进行服务端身份校验。 ServerKeyExchange消息的作用是，将需要服务端提供的密钥交换的额外参数，传给客户端。有的算法不需要额外参数，则ServerKeyExchange消息可不发送。 ServerHelloDone消息的作用是，通知客户端ServerHello阶段的数据均已发送完毕，等待客户端下一步消息。 ClientKeyExchange消息的作用是，将客户端需要为密钥交换提供的数据发送给服务端。 ChangeCipherSpec消息的作用，便是声明后续消息均采用密钥加密。在此消息后，我们在WireShark上便看不到明文信息了。 Finished消息的作用，是对握手阶段所有消息计算摘要，并发送给对方校验，避免通信过程中被中间人所篡改。 1.4 总结HTTPS如何保证通信安全，通过握手协议的介绍，我们已经有所了解。但是，在全面使用HTTPS前，我们还需要考虑一个众所周知的问题——HTTPS性能。相对HTTP协议来说，HTTPS协议建立数据通道的更加耗时，若直接部署到App中，势必降低数据传递的效率，间接影响用户体验。 2. HTTP 22.1 HTTP1.x协议随着互联网的快速发展，HTTP1.x协议得到了迅猛发展，但当App一个页面包含了数十个请求时，HTTP1.x协议的局限性便暴露了出来： 每个请求与响应需要单独建立链路进行请求(Connection字段能够解决部分问题)，浪费资源。 每个请求与响应都需要添加完整的头信息，应用数据传输效率较低。 默认没有进行加密，数据在传输过程中容易被监听与篡改。 2.2 HTTP 2介绍HTTP2正是为了解决HTTP1.x暴露出来的问题而诞生的。 说到HTTP2不得不提spdy。由于HTTP1.x暴露出来的问题，Google设计了全新的名为spdy的新协议。spdy在五层协议栈的TCP层与HTTP层引入了一个新的逻辑层以提高效率。spdy是一个中间层，对TCP层与HTTP层有很好的兼容，不需要修改HTTP层即可改善应用数据传输速度。spdy通过多路复用技术，使客户端与服务器只需要保持一条链接即可并发多次数据交互，提高了通信效率。而HTTP2便士基于spdy的思路开发的。通过流与帧概念的引入，继承了spdy的多路复用，并增加了一些实用特性。 新特性： 多路复用 压缩头信息 对请求划分优先级 支持服务端Push消息到客户端 HTTP2目前在实际使用中，只用于HTTPS协议场景下，通过握手阶段ClientHello与ServerHello的extension字段协商而来，所以目前HTTP2的使用场景，都是默认安全加密的。 查看了wiki发现： Netty and OkHttp are the only two implementations supported by Spring. 2.3 协议协商HTTP2协议的协商是在握手阶段进行的。 协商的方式是通过握手协议extension扩展字段进行扩展，新增Application Layer Protocol Negotiation字段进行协商。 在握手协议的ClientHello阶段，客户端将所支持的协议列表填入Application Layer Protocol Negotiation字段，供服务端进行挑选。 2.4 多路复用Multipexing在HTTP2中，同一域名下的请求，可通过同一条TCP链路进行传输，使多个请求不必单独建立链路，节省建立链路的开销。 为了达到这个目的，HTTP2提出了流与帧的概念，流代表请求与响应，而请求与响应具体的数据则包装为帧，对链路中传输的数据通过流ID与帧类型进行区分处理。下图是多路复用的抽象图，每个块代表一帧，而相同颜色的块则代表是同一个流。 归纳下okhttp的多路复用实现思路： 通过请求的Address与连接池中现有连接Address依次匹配，选出可用的Connection。 通过Http2xStream创建的FramedStream在发送了请求后，将FramedStream对象与StreamID的映射关系缓存到FramedConnection中。 收到消息后，FramedConnection解析帧信息，在Map中通过解析的StreamID选出缓存的FramedStream，并唤醒FramedStream进行Response的处理。 2.5 压缩头信息HTTP2为了解决HTTP1.x中头信息过大导致效率低下的问题，提出的解决方案便是压缩头部信息。具体的压缩方式，则引入了HPACK。 HPACK压缩算法是专门为HTTP2头部压缩服务的。为了达到压缩头部信息的目的，HPACK将头部字段缓存为索引，通过索引ID代表头部字段。客户端与服务端维护索引表，通信过程中尽可能采用索引进行通信，收到索引后查询索引表，才能解析出真正的头部信息。 HPACK索引表划分为动态索引表与静态索引表，动态索引表是HTTP2协议通信过程中两端动态维护的索引表，而静态索引表是硬编码进协议中的索引表。 作为分析HPACK压缩头信息的基础，需要先介绍HPACK对索引以及头部字符串的表示方式。 索引 索引以整型数字表示，由于HPACK需要考虑压缩与编解码问题，所以整型数字结构定义下图所示： 类别标识:通过类别标识进行HPACK类别分类，指导后续编解码操作，常见的有1，01，01000000等八个类别。 首字节低位整型:首字节排除类别标识的剩余位，用于表示低位整型。若数值大于剩余位所能表示的容量，则需要后续字节表示高位整型。 结束标识:表示此字节是否为整型解析终止字节。 高位整型:字节余下7bit，用于填充整型高位。]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
        <tag>HTTP2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 集群基础]]></title>
    <url>%2F2017%2F08%2F10%2Fmongodb%E9%9B%86%E7%BE%A4%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[1. MongoDB介绍 MongoDB 是一个可扩展的高性能,开源,模式自由,面向文档的数据库。 它使用 C++编写。MongoDB 包含一下特点: 面向集合的存储:适合存储对象及JSON形式的数据。 动态查询:Mongo 支持丰富的查询方式,查询指令使用 JSON 形式的标记,可轻易查询文档中内嵌的对象及数组。 完整的索引支持:包括文档内嵌对象及数组。Mongo 的查询优化器会分析查询表达式,并生成一个高效的查询计划。 查询监视:Mongo包含一个监控工具用于分析数据库操作性能。 复制及自动故障转移:Mongo 数据库支持服务器之间的数据复制,支持主-从模式及服务器之间的相互复制。复制的主要目的是提供冗余及自动故障转移。 高效的传统存储方式:支持二进制数据及大型对象(如:照片或图片)。 自动分片以支持云级别的伸缩性:自动分片功能支持水平的数据库集群,可动态添加额外的机器。 2.Replica Set集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。 Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。 默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时Java客户端提供了简单的配置方式，可以不必直接对数据库进行操作。 仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。我开始也不相信必须要有仲裁节点，但是自己也试过没仲裁节点的话，主节点挂了备节点还是备节点，所以咱们还是需要它的。 3.Sharding 和Replica Set类似，都需要一个仲裁节点，但是Sharding还需要配置节点和路由节点。 集群搭建方式首选Replica Set，只有真的是大数据，Sharding才能显现威力，毕竟备节点同步数据是需要时间的。Sharding可以将多片数据集中到路由节点上进行一些对比，然后将数据返回给客户端，但是效率还是比较低的说。 我自己有测试过，不过具体的机器配置已经不记得了。Replica Set的ips在数据达到1400w条时基本能达到1000左右，而Sharding在300w时已经下降到500ips了，两者的单位数据大小大概是10kb。大家在应用的时候还是多多做下性能测试，毕竟不像Redis有benchmark。 Mongodb现在用的还是比较多的，但是个人觉得配置太多了。我看官网都看了好多天，才把集群搭建的配置和注意要点弄明白。而且用过的人应该知道mongodb吃内存的问题，解决办法只能通过ulimit来控制内存使用量，但是如果控制不好的话，mongodb会挂掉 PS: 后面继续补充。]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 入门]]></title>
    <url>%2F2017%2F07%2F18%2Fspring-cloud%2F</url>
    <content type="text"><![CDATA[1. 微服务架构微服务架构（Micro-Service Archeticture）是当下流行的架构风格，旨在通过将功能模块分解到各个独立的子系统中以实现解耦，它并没有一成不变的规定，而是需要根据业务来做设计[李贞昊,2017]。微服务架构中，每个微服务模块只是对简单、独立、明确的任务进行处理，通过REST API返回处理结果给外部。在微服务推广实践角度来看，微服务将整个系统进行拆分，拆分成更小的粒度，保持这些服务独立运行，应用容器化技术将微服务独立运行在容器中。过去设计架构时，是在内存中以参数或对象的方式实现粒度细化。微服务使用各个子服务控制模块的思想代替总线。不同的业务要求，服务控制模块至少包含服务的发布、注册、路由、代理功能。 2. vs 单体应用架构微服务架构模式相比于单体应用架构，有很多优势。 首先，巨大的单体式应用拆分为多个微服务，降低了复杂性。在具有之前单体应用功能的同时，单体应用被拆分为多个可管理的微服务。每个微服务都具有定义清楚的边界，使用远程过程调用（RPC）或者消息驱动API。拆分后的微服务模块，粒度小，很容易开发和维护。微服务架构模式降低了单体式编码的难度，并且功能提供了模块化的解决方案。 第二，微服务架构下，专门开发团队负责开发一个子服务。每个开发团队可以自主选择技术栈，提供API接口。当然，许多公司将技术栈统一，只提供特定选择的技术。然后，这种自由使得开发团队不需要被迫使用特定的那些技术，他们可以自由地选择适合该微服务的技术。甚至于，重构之前的代码也变得很便捷。 第三，每个微服务都是独立的部署。开发团队不再需要协调其它服务部署对本服务的影响。这样的特性大大加快了部署速度。微服务架构模式使得持续化部署成为可能。 最后，微服务架构模式使得每个微服务应用都可以被独立扩展。单体架构应用也可以横向扩展，即整个应用完整的复制到不同的节点。当应用的不同组件在扩展需求上存在差异时，微服务架构便体现出其优越性。通过在不同的基础设施之间实现扩展，这些服务能够有效地降低风险[陈春霞, 2016]。 3. Spring Cloud开源框架Spring Cloud是一个基于Spring Boot实现的云应用开发工具，它为基于JVM的云应用开发中的服务发现与注册、熔断机制、路由、全局锁、中心配置管理、控制总线、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式[翟永超,2016]。Spring Cloud整体架构图如图1.1所示。 Spring Cloud整体架构中如下几个基础服务模块：微服务配置管理、API网关服务、服务发现与注册和消息总线模块。 spring-cloud-config，微服务配置管理，即为上图的config service服务模块，为服务端提供了分布式环境的中央配置支持。配置服务器为各应用的所有环境提供了一个中心化的外部配置。它完成了对服务端Spring-Env和配置源抽象的映射，所以config服务不仅适用于Spring框架构建的应用，也可以使用在其他语言的应用程序。作为一个应用，可以通过部署管道来进行测试或者投入生产，分别为这些环境创建配置，并且在需要迁移环境的时候获取对应的配置来运行。 API网关，本系统使用netflix的zuul框架，作为系统的统一入口，具有负载均衡、服务路由、服务过滤等功能。 服务发现与注册有多种开源组件支持，比如zookeeper、etcd、netflix公司的Eureka，以及本系统使用的Consul。服务发现是一个服务将其地址信息在中心注册节点进行注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，具体还会包括认证信息、使用协议、版本号等信息，以及关于应用服务环境的细节信息。一个应用服务或者组件通过服务发现可以掌握其运行环境以及其它应用服务或组件的信息。用户配置一个服务发现工具之后，就可以将实际容器与运行配置分离开。]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析REST与HTTP]]></title>
    <url>%2F2017%2F07%2F10%2FREST%E4%B8%8EHTTP%2F</url>
    <content type="text"><![CDATA[幂等性Methods can also have the property of &quot;idempotence&quot; in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request. 安全操作与幂指相等特性（Safety /Idempotence）HTTP 的 GET、HEAD 请求本质上应该是安全的调用，即：GET、HEAD 调用不会有任何的副作用，不会造成服务器端状态的改变。对于服务器来说，客户端对某一 URI 做 n 次的 GET、HAED 调用，其状态与没有做调用是一样的，不会发生任何的改变。 HTTP 的 PUT、DELTE 调用，具有幂指相等特性 , 即：客户端对某一 URI 做 n 次的 PUT、DELTE 调用，其效果与做一次的调用是一样的。HTTP 的 GET、HEAD 方法也具有幂指相等特性。HTTP 这些标准方法在原则上保证你的分布式系统具有这些特性，以帮助构建更加健壮的分布式系统。 当然作为设计的基础，几个必须的原则还是要遵守的： 当标准合理的时候遵守标准。 API应该对程序员友好，并且在浏览器地址栏容易输入。 API应该简单，直观，容易使用的同时优雅。 API应该具有足够的灵活性来支持上层ui。 API设计权衡上述几个原则。 HTTPhttp请求由三部分组成，分别是：请求行、消息报头、请求正文. http 1.1/2 http://www.blogjava.net/yongboy/archive/2015/03/23/423751.html HTTP/1.1，HTTP客户端无法重试非幂等请求，尤其在错误发生的时候，由于无法检测错误性质这会对重试带来不利的影响。 HTTP/2不允许使用连接特定头部字段 新增的5个头部 推送机制的一些特性需求 RST_STREAM等帧标志位的使用]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>REST</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
</search>